{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0d9ddce1-9f7d-4877-95a0-a071393c9bc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from data_loader import bench, squat, deadlift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3497d1bc-7a0a-4e58-b769-934688aa6d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tf.Tensor([0. 0. 0.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "class RepCount(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(RepCount, self).__init__()\n",
    "        self.values = tf.constant([0], dtype=tf.float32)\n",
    "\n",
    "    def heaviside_custom(self, x, values):\n",
    "        ones = tf.ones_like(x)\n",
    "        zeros = tf.zeros_like(x)\n",
    "        return tf.where(x > 0, ones, tf.where(x < 0, zeros, values))\n",
    "\n",
    "    def call(self, tens):\n",
    "        t = self.heaviside_custom(tens, self.values)\n",
    "        b = t[1:] - t[:-1]\n",
    "        mask = tf.reduce_any(tf.not_equal(b, 0), axis=1)\n",
    "        b = tf.boolean_mask(b, mask)\n",
    "        b = tf.where(tf.equal(b, -1), tf.zeros_like(b), b)\n",
    "        return tf.reduce_sum(b, axis=0)\n",
    "\n",
    "def preprocessing(dummy_input):\n",
    "    t = np.mean(dummy_input, axis=0) \n",
    "    padding = np.zeros((128 - dummy_input.shape[0] % 128, dummy_input.shape[1]))\n",
    "    dummy_input = np.concatenate([dummy_input, padding], axis=0)\n",
    "    dummy_input = dummy_input - t\n",
    "    dummy_input_2 = np.reshape(dummy_input, (-1, 128, 3))\n",
    "    dummy_input_3 = tf.constant(dummy_input_2, dtype=tf.float32)\n",
    "    return dummy_input_3\n",
    "\n",
    "model = RepCount()\n",
    "dummy_input = preprocessing((bench[1][['gravityX', 'gravityY', 'gravityZ']]).dropna().to_numpy())\n",
    "inp = dummy_input[0]\n",
    "output = model(inp)\n",
    "print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a968b78f-cd1c-43c6-b48a-5c0f07d4003c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model2/assets\n"
     ]
    }
   ],
   "source": [
    "saved_model_dir = \"models/model2\"\n",
    "tf.saved_model.save(model, saved_model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7ee72049-627b-495a-9dcb-24f92281b18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1741828507.013490 7847760 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1741828507.013501 7847760 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-03-12 18:15:07.013638: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: models/model2\n",
      "2025-03-12 18:15:07.013795: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-03-12 18:15:07.013800: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: models/model2\n",
      "2025-03-12 18:15:07.014700: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-03-12 18:15:07.017355: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: models/model2\n",
      "2025-03-12 18:15:07.019340: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 5703 microseconds.\n",
      "2025-03-12 18:15:07.031927: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:3893] Estimated count of arithmetic ops: 381  ops, equivalently 190  MACs\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"rep_count_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d414644-649a-418f-8dee-0f338e9fe2c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "644de5f5-9c56-40ab-9cb6-49f310bfb94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input details: [{'name': 'serving_default_inputs:0', 'index': 0, 'shape': array([128,   3], dtype=int32), 'shape_signature': array([128,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Output details: [{'name': 'PartitionedCall:0', 'index': 29, 'shape': array([3], dtype=int32), 'shape_signature': array([3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"rep_count_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(\"Input details:\", input_details)\n",
    "print(\"Output details:\", output_details)\n",
    "\n",
    "input_shape = input_details[0]['shape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "261d15b6-05f2-4103-b524-f9f2520bba80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 128, 3])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7d5df62b-e031-4c90-8e3f-c25aea2af8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpreter.resize_tensor_input(input_details[0]['index'], dummy_input.shape)\n",
    "#interpreter.allocate_tensors()  \n",
    "interpreter.set_tensor(input_details[0]['index'], dummy_input[0])\n",
    "interpreter.invoke()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "eec4b967-652e-4a1b-b448-c64658e9c64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output: [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "output_details = interpreter.get_output_details()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Model output:\", output_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a4faa2-a4e2-49a6-86d8-e19d100ed3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
