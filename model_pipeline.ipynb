{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d9ddce1-9f7d-4877-95a0-a071393c9bc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from data_loader import bench, squat, deadlift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3497d1bc-7a0a-4e58-b769-934688aa6d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tf.Tensor([ 1.  1. 13.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "class RepCount(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(RepCount, self).__init__()\n",
    "        self.values = tf.constant([0], dtype=tf.float32)\n",
    "\n",
    "    def heaviside_custom(self, x, values):\n",
    "        ones = tf.ones_like(x)\n",
    "        zeros = tf.zeros_like(x)\n",
    "        return tf.where(x > 0, ones, tf.where(x < 0, zeros, values))\n",
    "\n",
    "    def call(self, tens):\n",
    "        t = self.heaviside_custom(tens, self.values)\n",
    "        b = t[1:] - t[:-1]\n",
    "        mask = tf.reduce_any(tf.not_equal(b, 0), axis=1)\n",
    "        b = tf.boolean_mask(b, mask)\n",
    "        b = tf.where(tf.equal(b, -1), tf.zeros_like(b), b)\n",
    "        return tf.reduce_sum(b, axis=0)\n",
    "\n",
    "model = RepCount()\n",
    "dummy_input = tf.constant((bench[0][['gravityX', 'gravityY', 'gravityZ']]).dropna().to_numpy(), dtype=tf.float32)\n",
    "output = model(dummy_input)\n",
    "print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a968b78f-cd1c-43c6-b48a-5c0f07d4003c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model2/assets\n"
     ]
    }
   ],
   "source": [
    "saved_model_dir = \"models/model2\"\n",
    "tf.saved_model.save(model, saved_model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ee72049-627b-495a-9dcb-24f92281b18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1741807061.384770 7799673 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1741807061.384781 7799673 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-03-12 12:17:41.384926: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: models/model2\n",
      "2025-03-12 12:17:41.385071: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-03-12 12:17:41.385076: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: models/model2\n",
      "2025-03-12 12:17:41.386087: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-03-12 12:17:41.388760: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: models/model2\n",
      "2025-03-12 12:17:41.390834: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 5909 microseconds.\n",
      "2025-03-12 12:17:41.403685: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:3893] Estimated count of arithmetic ops: 0.013 M  ops, equivalently 0.006 M  MACs\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"rep_count_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d414644-649a-418f-8dee-0f338e9fe2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "Input details: [{'name': 'serving_default_inputs:0', 'index': 0, 'shape': array([4174,    3], dtype=int32), 'shape_signature': array([4174,    3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Output details: [{'name': 'PartitionedCall:0', 'index': 29, 'shape': array([3], dtype=int32), 'shape_signature': array([3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "dummy_input = tf.constant((bench[1][['gravityX', 'gravityY', 'gravityZ']]).dropna().to_numpy(), dtype=tf.float32)\n",
    "print(dummy_input.shape[0] % 128)\n",
    "dummy_input = tf.reduce_mean(dummy_input)\n",
    "\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=\"rep_count_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(\"Input details:\", input_details)\n",
    "print(\"Output details:\", output_details)\n",
    "\n",
    "input_shape = input_details[0]['shape']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "261d15b6-05f2-4103-b524-f9f2520bba80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4174,    3], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d5df62b-e031-4c90-8e3f-c25aea2af8f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given shapes, [1173,3], [4174,3] and [1], are not broadcastable.Node number 4 (SELECT_V2) failed to prepare.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m interpreter\u001b[38;5;241m.\u001b[39mresize_tensor_input(input_details[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m], dummy_input\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 2\u001b[0m \u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallocate_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m      3\u001b[0m interpreter\u001b[38;5;241m.\u001b[39mset_tensor(input_details[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m], dummy_input)\n\u001b[1;32m      4\u001b[0m interpreter\u001b[38;5;241m.\u001b[39minvoke()\n",
      "File \u001b[0;32m~/Documents/python_projects/senior_design/.env/lib/python3.9/site-packages/tensorflow/lite/python/interpreter.py:534\u001b[0m, in \u001b[0;36mInterpreter.allocate_tensors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mallocate_tensors\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    533\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_safe()\n\u001b[0;32m--> 534\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAllocateTensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given shapes, [1173,3], [4174,3] and [1], are not broadcastable.Node number 4 (SELECT_V2) failed to prepare."
     ]
    }
   ],
   "source": [
    "interpreter.resize_tensor_input(input_details[0]['index'], dummy_input.shape)\n",
    "interpreter.allocate_tensors()  \n",
    "interpreter.set_tensor(input_details[0]['index'], dummy_input)\n",
    "interpreter.invoke()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec4b967-652e-4a1b-b448-c64658e9c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_details = interpreter.get_output_details()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Model output:\", output_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "190f1990-db47-42ed-828e-3b405556871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([[1, 1], [1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9bf7cdee-d4d5-48e0-8fa7-52f52e5a2013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[1, 1],\n",
       "       [1, 1]], dtype=int32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6eab291-5908-4172-8785-3cfa2f1dc756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=int32, numpy=\n",
       "array([[0, 0, 0, 0],\n",
       "       [0, 1, 1, 0],\n",
       "       [0, 1, 1, 0],\n",
       "       [0, 0, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.pad(a, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01f7dde-1b29-47fa-8897-41a8b3f63df7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
